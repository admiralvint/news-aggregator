# ğŸ“° News Aggregator

A self-hosted news aggregator that fetches articles from RSS feeds, automatically categorizes them, and generates AI-powered summaries using [Ollama](https://ollama.ai/).

![Python](https://img.shields.io/badge/Python-3.12-blue)
![Docker](https://img.shields.io/badge/Docker-Compose-blue)
![License](https://img.shields.io/badge/License-MIT-green)

## âœ¨ Features

- **Multi-source RSS Aggregation** â€” Fetch from any RSS/Atom feed (tech news, gaming, motorsport, etc.)
- **Async Parallel Fetching** â€” Fast concurrent scraping with rate limiting
- **AI Summaries** â€” Generate article summaries via Ollama LLM (optional)
- **Auto-categorization** â€” Automatically categorize articles by topic keywords
- **Duplicate Detection** â€” Content-hash based deduplication
- **Web Interface** â€” Clean Flask-based UI with filtering by source, category, and date
- **Health Monitoring** â€” Built-in `/health` endpoint for container monitoring
- **Docker-ready** â€” Easy deployment with Docker Compose

## ğŸ› ï¸ Tech Stack

| Component | Technology |
|-----------|------------|
| Backend | Python 3.12, Flask |
| Scraping | aiohttp, feedparser, BeautifulSoup4 |
| Database | SQLite |
| Summarization | Ollama (any compatible model) |
| Containerization | Docker, Docker Compose |

## ğŸš€ Quick Start

### Prerequisites

- Docker and Docker Compose
- (Optional) Ollama server for AI summaries

### 1. Clone the repository

```bash
git clone https://github.com/admiralvint/news-aggregator.git
cd news-aggregator
```

### 2. Configure your sources

Edit `config/sources.yaml` to add your preferred news sources:

```yaml
scrape_interval_minutes: 240
retention_days: 7

sources:
  - name: "Ars Technica"
    url: "https://feeds.arstechnica.com/arstechnica/index"
    type: "rss"
    enabled: true

  - name: "The Verge"
    url: "https://www.theverge.com/rss/index.xml"
    type: "rss"
    enabled: true

# Optional: LLM for summaries
llm:
  host: "192.168.1.100"  # Your Ollama server IP
  port: 11434
  model: "llama3"
  summary_style: "standard"  # Options: brief, standard, detailed, bullets
```

### 3. Build and run

```bash
docker compose build
docker compose up -d
```

### 4. Access the web interface

Open **http://localhost:5000** in your browser.

## ğŸ“ Project Structure

```
news-aggregator/
â”œâ”€â”€ config/
â”‚   â””â”€â”€ sources.yaml      # News sources & LLM configuration
â”œâ”€â”€ data/
â”‚   â””â”€â”€ articles.db       # SQLite database (auto-created)
â”œâ”€â”€ scraper/
â”‚   â”œâ”€â”€ scraper.py        # Main scraping & summarization logic
â”‚   â”œâ”€â”€ web.py            # Flask web interface
â”‚   â””â”€â”€ requirements.txt  # Python dependencies
â”œâ”€â”€ docker-compose.yml    # Container orchestration
â””â”€â”€ Dockerfile            # Container image definition
```

## âš™ï¸ Configuration

### Source Types

| Type | Description |
|------|-------------|
| `rss` | Standard RSS/Atom feeds |
| `hackernews` | Hacker News API integration |

### Summary Styles

Configure in `sources.yaml` under `llm.summary_style`:

| Style | Description |
|-------|-------------|
| `brief` | 1-2 sentence summary |
| `standard` | 4-5 sentence summary (default) |
| `detailed` | Comprehensive paragraph |
| `bullets` | 3-5 bullet points |

### Environment Variables

| Variable | Default | Description |
|----------|---------|-------------|
| `TZ` | `UTC` | Container timezone |

## ğŸ”§ Running Without Docker

```bash
# Install dependencies
pip install -r scraper/requirements.txt

# Run the scraper (background process)
python scraper/scraper.py &

# Run the web interface
python scraper/web.py
```

## ğŸ“¡ API Endpoints

| Endpoint | Description |
|----------|-------------|
| `GET /` | Web interface with article list |
| `GET /health` | Health check with article stats |

### Query Parameters (Web Interface)

| Parameter | Description |
|-----------|-------------|
| `source` | Filter by source name |
| `category` | Filter by auto-detected category |
| `days` | Show articles from last N days (1, 3, 7, 14, 30) |

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Submit a pull request

## ğŸ“„ License

MIT License â€” feel free to use and modify as needed.
